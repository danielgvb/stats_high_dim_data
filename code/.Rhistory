vars_to_binn <- c('rating', 'status', 'wd_date_approval', 'satus', 'work',
'max_edication', 'city_born', 'agency')
# Initialize a list to store binning objects for each variable
binning_list <- list()
# Iterate over the variables to create binning for each
for (var in vars_to_binn) {
binning_list[[var]] <- woeBinning::woe.binning(
df = train_data,
target.var = "default_90", # Target variable
pred.var = var,           # Current variable to bin
min.perc.total = 0.05,    # Minimum percentage per bin
min.perc.class = 0.01     # Minimum percentage of target class per bin
)
}
# Iterate over the variables to create binning for each
for (var in vars_to_binn) {
print(var)
binning_list[[var]] <- woeBinning::woe.binning(
df = train_data,
target.var = "default_90", # Target variable
pred.var = var,           # Current variable to bin
min.perc.total = 0.05,    # Minimum percentage per bin
min.perc.class = 0.01     # Minimum percentage of target class per bin
)
}
vars_to_binn <- c('rating', 'status', 'wd_date_approval', 'status', 'work',
'max_edication', 'city_born', 'agency')
# Initialize a list to store binning objects for each variable
binning_list <- list()
# Iterate over the variables to create binning for each
for (var in vars_to_binn) {
print(var)
binning_list[[var]] <- woeBinning::woe.binning(
df = train_data,
target.var = "default_90", # Target variable
pred.var = var,           # Current variable to bin
min.perc.total = 0.05,    # Minimum percentage per bin
min.perc.class = 0.01     # Minimum percentage of target class per bin
)
}
vars_to_binn <- c('rating', 'status', 'wd_date_approval', 'status', 'work',
'max_education', 'city_born', 'agency')
# Initialize a list to store binning objects for each variable
binning_list <- list()
# Iterate over the variables to create binning for each
for (var in vars_to_binn) {
print(var)
binning_list[[var]] <- woeBinning::woe.binning(
df = train_data,
target.var = "default_90", # Target variable
pred.var = var,           # Current variable to bin
min.perc.total = 0.05,    # Minimum percentage per bin
min.perc.class = 0.01     # Minimum percentage of target class per bin
)
}
# Display binning summary for each variable
for (var in vars_to_binn) {
cat("\nBinning summary for", var, ":\n")
print(woeBinning::woe.binning.table(binning_list[[var]]))
}
# Apply binning transformations to the dataset
data_binned <- train_data
# Iterate over the binned variables and generate plots
for (var in vars_to_binn) {
# Construct the binned variable name
binned_var <- paste0(var, ".binned")
# Check if the binned variable exists in the data
if (binned_var %in% names(data_binned)) {
# Generate and print the plot
plot <- ggplot(data_binned, aes_string(x = binned_var, fill = "factor(default_90)")) +
geom_bar(position = "fill") +  # Stacked proportions
labs(
title = paste("Bar Plot of", binned_var, "by Target"),
x = var,
y = "Proportion",
fill = "Target"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Print the plot
print(plot)
} else {
cat("Binned variable", binned_var, "does not exist in the data.\n")
}
}
# Apply binning transformations to the dataset
data_binned <- train_data
# Iterate over the binned variables and generate plots
for (var in vars_to_binn) {
# Construct the binned variable name
binned_var <- paste0(var, ".binned")
# Check if the binned variable exists in the data
if (binned_var %in% names(data_binned)) {
# Generate and print the plot
plot <- ggplot(data_binned, aes_string(x = binned_var, fill = "factor(default_90)")) +
geom_bar(position = "fill") +  # Stacked proportions
labs(
title = paste("Bar Plot of", binned_var, "by Target"),
x = var,
y = "Proportion",
fill = "Target"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Print the plot
print(plot)
} else {
cat("Binned variable", binned_var, "does not exist in the data.\n")
}
}
vars_to_binn <- c('rating', 'status', 'wd_date_approval', 'status', 'work',
'max_education', 'city_born', 'agency')
# Initialize a list to store binning objects for each variable
binning_list <- list()
# Iterate over the variables to create binning for each
for (var in vars_to_binn) {
print(var)
binning_list[[var]] <- woeBinning::woe.binning(
df = train_data,
target.var = "default_90", # Target variable
pred.var = var,           # Current variable to bin
min.perc.total = 0.05,    # Minimum percentage per bin
min.perc.class = 0.01     # Minimum percentage of target class per bin
)
}
# Display binning summary for each variable
for (var in vars_to_binn) {
cat("\nBinning summary for", var, ":\n")
print(woeBinning::woe.binning.table(binning_list[[var]]))
}
# Apply binning transformations to the dataset
data_binned <- train_data
for (var in vars_to_binn) {
data_binned <- woeBinning::woe.binning.deploy(data_binned, binning_list[[var]])
}
View(data_binned)
# Iterate over the binned variables and generate plots
for (var in vars_to_binn) {
# Construct the binned variable name
binned_var <- paste0(var, ".binned")
# Check if the binned variable exists in the data
if (binned_var %in% names(data_binned)) {
# Generate and print the plot
plot <- ggplot(data_binned, aes_string(x = binned_var, fill = "factor(default_90)")) +
geom_bar(position = "fill") +  # Stacked proportions
labs(
title = paste("Bar Plot of", binned_var, "by Target"),
x = var,
y = "Proportion",
fill = "Target"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Print the plot
print(plot)
} else {
cat("Binned variable", binned_var, "does not exist in the data.\n")
}
}
duplicate_columns <- names(data_binned)[duplicated(names(data_binned))]
if (length(duplicate_columns) > 0) {
cat("Duplicate columns found:", paste(duplicate_columns, collapse = ", "), "\n")
} else {
cat("No duplicate columns found.\n")
}
vars_to_binn <- c('rating', 'status', 'wd_date_approval', 'work',
'max_education', 'city_born', 'agency')
# Initialize a list to store binning objects for each variable
binning_list <- list()
# Iterate over the variables to create binning for each
for (var in vars_to_binn) {
print(var)
binning_list[[var]] <- woeBinning::woe.binning(
df = train_data,
target.var = "default_90", # Target variable
pred.var = var,           # Current variable to bin
min.perc.total = 0.05,    # Minimum percentage per bin
min.perc.class = 0.01     # Minimum percentage of target class per bin
)
}
# Display binning summary for each variable
for (var in vars_to_binn) {
cat("\nBinning summary for", var, ":\n")
print(woeBinning::woe.binning.table(binning_list[[var]]))
}
# Apply binning transformations to the dataset
data_binned <- train_data
for (var in vars_to_binn) {
data_binned <- woeBinning::woe.binning.deploy(data_binned, binning_list[[var]])
}
# Iterate over the binned variables and generate plots
for (var in vars_to_binn) {
# Construct the binned variable name
binned_var <- paste0(var, ".binned")
# Check if the binned variable exists in the data
if (binned_var %in% names(data_binned)) {
# Generate and print the plot
plot <- ggplot(data_binned, aes_string(x = binned_var, fill = "factor(default_90)")) +
geom_bar(position = "fill") +  # Stacked proportions
labs(
title = paste("Bar Plot of", binned_var, "by Target"),
x = var,
y = "Proportion",
fill = "Target"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Print the plot
print(plot)
} else {
cat("Binned variable", binned_var, "does not exist in the data.\n")
}
}
# Plot the p-values
ggplot(chi2_results_df, aes(x = reorder(Variable, -P_value), y = P_value)) +
geom_bar(stat = "identity", fill = "skyblue") +
geom_hline(yintercept = 0.05, color = "red", linetype = "dashed") +  # Significance threshold
labs(title = "P-values from Chi-square Tests for Non-numeric Variables vs default_90",
x = "Variable",
y = "P-value") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
vars_to_binn <- c('rating', 'status', 'wd_date_approval', 'm_date_approval', 'work',
'max_education', 'city_born', 'agency')
# Initialize a list to store binning objects for each variable
binning_list <- list()
# Iterate over the variables to create binning for each
for (var in vars_to_binn) {
print(var)
binning_list[[var]] <- woeBinning::woe.binning(
df = train_data,
target.var = "default_90", # Target variable
pred.var = var,           # Current variable to bin
min.perc.total = 0.05,    # Minimum percentage per bin
min.perc.class = 0.01     # Minimum percentage of target class per bin
)
}
# Display binning summary for each variable
for (var in vars_to_binn) {
cat("\nBinning summary for", var, ":\n")
print(woeBinning::woe.binning.table(binning_list[[var]]))
}
# Apply binning transformations to the dataset
data_binned <- train_data
for (var in vars_to_binn) {
data_binned <- woeBinning::woe.binning.deploy(data_binned, binning_list[[var]])
}
# Iterate over the binned variables and generate plots
for (var in vars_to_binn) {
# Construct the binned variable name
binned_var <- paste0(var, ".binned")
# Check if the binned variable exists in the data
if (binned_var %in% names(data_binned)) {
# Generate and print the plot
plot <- ggplot(data_binned, aes_string(x = binned_var, fill = "factor(default_90)")) +
geom_bar(position = "fill") +  # Stacked proportions
labs(
title = paste("Bar Plot of", binned_var, "by Target"),
x = var,
y = "Proportion",
fill = "Target"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Print the plot
print(plot)
} else {
cat("Binned variable", binned_var, "does not exist in the data.\n")
}
}
View(data_binned)
# Apply binning to test data (under training rules)
test_data_binned <- test_data
for (var in vars_to_binn) {
# Check if the binning object exists and the variable is in test_data
if (!is.null(binning_list[[var]]) && var %in% names(test_data)) {
# Apply the binning to the test data
test_data_binned <- woeBinning::woe.binning.deploy(test_data_binned, binning_list[[var]])
} else {
cat("Skipping variable:", var, "as it is not found in test_data or binning_list.\n")
}
}
# Check the binned test data
head(test_data_binned)
# Drop original columns from train_data and test_data
train_data_binned <- data_binned[, !names(data_binned) %in% vars_to_binn]
test_data_binned <- test_data_binned[, !names(test_data_binned) %in% vars_to_binn]
# Model Training and Evaluation ------------------------
## Helper Functions------------------
# Define the function
calculate_metrics <- function(predicted_probs, actual_labels, threshold = 0.5) {
# Convert probabilities to binary predictions based on the threshold
predicted_labels <- ifelse(predicted_probs > threshold, 1, 0)
# Create confusion matrix
conf_matrix <- confusionMatrix(factor(predicted_labels), factor(actual_labels))
# Extract components of the confusion matrix
cm <- conf_matrix$table
TP <- cm[2, 2]  # True Positives
FP <- cm[1, 2]  # False Positives
TN <- cm[1, 1]  # True Negatives
FN <- cm[2, 1]  # False Negatives
# Manually calculate metrics
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)
accuracy <- (TP + TN) / sum(cm)
# Return results as a list
return(list(
Precision = precision,
Recall = recall,
F1 = f1_score,
Accuracy = accuracy
))
}
## Logistic Regression----------------
logistic_model <- glm(default_90 ~ ., data = train_data, family = binomial)
logistic_model_b <- glm(default_90 ~ ., data = data_binned, family = binomial)
# Make predictions on the test data
predicted_probs <- predict(logistic_model, newdata = test_data, type = "response")
predicted_probs_b <- predict(logistic_model_b, newdata = test_data_binned, type = "response")
summary(logistic_model_b)
vars_to_binn <- c('rating', 'status', 'wd_date_approval', 'm_date_approval', 'work',
'max_education', 'city_born', 'agency')
# Initialize a list to store binning objects for each variable
binning_list <- list()
# Iterate over the variables to create binning for each
for (var in vars_to_binn) {
print(var)
binning_list[[var]] <- woeBinning::woe.binning(
df = train_data,
target.var = "default_90", # Target variable
pred.var = var,           # Current variable to bin
min.perc.total = 0.05,    # Minimum percentage per bin
min.perc.class = 0.01     # Minimum percentage of target class per bin
)
}
# Display binning summary for each variable
for (var in vars_to_binn) {
cat("\nBinning summary for", var, ":\n")
print(woeBinning::woe.binning.table(binning_list[[var]]))
}
# Apply binning transformations to the dataset
data_binned <- train_data
for (var in vars_to_binn) {
data_binned <- woeBinning::woe.binning.deploy(data_binned, binning_list[[var]])
}
# Iterate over the binned variables and generate plots
for (var in vars_to_binn) {
# Construct the binned variable name
binned_var <- paste0(var, ".binned")
# Check if the binned variable exists in the data
if (binned_var %in% names(data_binned)) {
# Generate and print the plot
plot <- ggplot(data_binned, aes_string(x = binned_var, fill = "factor(default_90)")) +
geom_bar(position = "fill") +  # Stacked proportions
labs(
title = paste("Bar Plot of", binned_var, "by Target"),
x = var,
y = "Proportion",
fill = "Target"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Print the plot
print(plot)
} else {
cat("Binned variable", binned_var, "does not exist in the data.\n")
}
}
# Apply binning to test data (under training rules)
test_data_binned <- test_data
for (var in vars_to_binn) {
# Check if the binning object exists and the variable is in test_data
if (!is.null(binning_list[[var]]) && var %in% names(test_data)) {
# Apply the binning to the test data
test_data_binned <- woeBinning::woe.binning.deploy(test_data_binned, binning_list[[var]])
} else {
cat("Skipping variable:", var, "as it is not found in test_data or binning_list.\n")
}
}
# Check the binned test data
head(test_data_binned)
# Drop original columns from train_data and test_data
train_data_binned <- data_binned[, !names(data_binned) %in% vars_to_binn]
test_data_binned <- test_data_binned[, !names(test_data_binned) %in% vars_to_binn]
# Model Training and Evaluation ------------------------
## Helper Functions------------------
# Define the function
calculate_metrics <- function(predicted_probs, actual_labels, threshold = 0.5) {
# Convert probabilities to binary predictions based on the threshold
predicted_labels <- ifelse(predicted_probs > threshold, 1, 0)
# Create confusion matrix
conf_matrix <- confusionMatrix(factor(predicted_labels), factor(actual_labels))
# Extract components of the confusion matrix
cm <- conf_matrix$table
TP <- cm[2, 2]  # True Positives
FP <- cm[1, 2]  # False Positives
TN <- cm[1, 1]  # True Negatives
FN <- cm[2, 1]  # False Negatives
# Manually calculate metrics
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)
accuracy <- (TP + TN) / sum(cm)
# Return results as a list
return(list(
Precision = precision,
Recall = recall,
F1 = f1_score,
Accuracy = accuracy
))
}
## Logistic Regression----------------
logistic_model <- glm(default_90 ~ ., data = train_data, family = binomial)
logistic_model_b <- glm(default_90 ~ ., data = train_data_binned, family = binomial)
summary(logistic_model_b)
# Make predictions on the test data
predicted_probs <- predict(logistic_model, newdata = test_data, type = "response")
predicted_probs_b <- predict(logistic_model_b, newdata = test_data_binned, type = "response")
### Model Evaluation---------------
logit_metrics <- calculate_metrics(predicted_probs, test_data$default_90)
logit_metrics
logit_metrics_b <- calculate_metrics(predicted_probs_b, test_data_binned$default_90)
logit_metrics_b
### Post-Estimation Plots---------------
par(mfrow = c(2,2))
plot(logistic_model)
plot(logistic_model_b)
# reset grid
par(mfrow = c(1,1))
#### 1. ROC Curve and AUC ------------------------------------
# Predicted probabilities for the test data
predicted_prob <- predict(logistic_model, newdata = test_data, type = "response")
# True labels
true_labels <- test_data$default_90
roc_curve <- roc(true_labels, predicted_prob)
auc_value <- auc(roc_curve)
# Plot ROC Curve
par(mfrow = c(1, 2))  # Set plot layout for ROC and PR curves side by side
plot(roc_curve, col = "blue", main = paste("ROC Curve (AUC =", round(auc_value, 2), ")"))
abline(a = 0, b = 1, lty = 2, col = "gray")
#### 2. Precision-Recall (PR) Curve --------------------------
# Generate PR Curve
pr_curve <- pr.curve(scores.class0 = predicted_prob[true_labels == 1],
scores.class1 = predicted_prob[true_labels == 0],
curve = TRUE)
# Plot PR Curve
plot(pr_curve, main = paste("Precision-Recall Curve (AUC =", round(pr_curve$auc.integral, 2), ")"),
col = "red", xlab = "Recall", ylab = "Precision")
# Predicted classes
predicted_class <- ifelse(predicted_prob > 0.5, 1, 0)
# Confusion matrix
conf_matrix <- table(Predicted = predicted_class, Actual = test_data$default_90)
# Heatmap
ggplot(as.data.frame(conf_matrix), aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
geom_text(aes(label = Freq), color = "black") +
labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
theme_minimal()
# Function to find the optimal threshold
find_optimal_threshold <- function(predicted_probs, actual_labels, thresholds) {
results <- data.frame(Threshold = numeric(), Precision = numeric(),
Recall = numeric(), F1 = numeric(), Accuracy = numeric())
for (threshold in thresholds) {
# Safeguard against confusion matrices that don't return 4 cells
tryCatch({
metrics <- calculate_metrics(predicted_probs, actual_labels, threshold)
results <- rbind(results, c(Threshold = threshold, metrics))
}, error = function(e) {})
}
# Convert results to data frame
results <- as.data.frame(results)
# Filter for valid rows (non-NA F1 scores)
results <- results[!is.na(results$F1), ]
# Find the threshold that maximizes F1 score
optimal_threshold <- results$Threshold[which.max(results$F1)]
return(list(OptimalThreshold = optimal_threshold, Metrics = results))
}
plot_metrics <- function(metrics) {
# Reshape data for ggplot2
metrics_long <- reshape2::melt(metrics, id.vars = "Threshold",
variable.name = "Metric", value.name = "Value")
# Plot metrics
ggplot(metrics_long, aes(x = Threshold, y = Value, color = Metric)) +
geom_line() +
labs(title = "Metrics Across Thresholds", x = "Threshold", y = "Value") +
theme_minimal()
}
# precision drops significantly, indicating that the model-
#- misclassifies many observations as positive when predicting defaults.
# Define a range of thresholds to evaluate
thresholds <- seq(0, 1, by = 0.05)  # Example grid of thresholds
thesholds_logit<- find_optimal_threshold(predicted_prob, true_labels, thresholds)
thresholds_logit<- find_optimal_threshold(predicted_prob, true_labels, thresholds)
plot_metrics(thresholds_logit)
thresholds_logit
# Predicted classes
predicted_class <- ifelse(predicted_prob > 0.25, 1, 0)
# Confusion matrix
conf_matrix <- table(Predicted = predicted_class, Actual = test_data$default_90)
# Heatmap
ggplot(as.data.frame(conf_matrix), aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
geom_text(aes(label = Freq), color = "black") +
labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
theme_minimal()
# for binned data
thresholds_logit_b <- find_optimal_threshold(predicted_probs_b, true_labels, thresholds)
thresholds_logit_b
plot_metrics(thresholds_logit_b)
