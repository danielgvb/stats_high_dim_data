plot(cv_fit_gglasso, main = "Cross-Validation for Group Lasso")
abline(v = log(lambda_min_gl), col = "blue", lty = 2, lwd = 2)  # Vertical line for lambda.min
abline(v = log(lambda_1se_gl), col = "red", lty = 2, lwd = 2)   # Vertical line for lambda.1se
legend("topright", legend = c("lambda.min", "lambda.1se"), col = c("blue", "red"), lty = 2, lwd = 2)
### Fit the Final Group Lasso Model
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
group_lasso_model <- gglasso(
x = X_train,
y = y_train,
group = group_vector,
loss = "logit",
lambda = lambda_min_gl
)
stopCluster(cl)
### 7.6.3 Model Evaluation ------------------------------
# Predicted probabilities
train_log_odds_gl <- predict(group_lasso_model, newx = X_train, type = "link")
test_log_odds_gl  <- predict(group_lasso_model, newx = X_test,  type = "link")
train_predicted_probs_gl <- 1 / (1 + exp(-train_log_odds_gl))
test_predicted_probs_gl  <- 1 / (1 + exp(-test_log_odds_gl ))
gl_metrics <- calculate_metrics(test_predicted_probs_gl, test_true_labels, 0.5)
#### ROC Curve and AUC-------------
roc_curve_gl <- roc(test_true_labels, test_predicted_probs_gl)
auc_value_gl <- auc(roc_curve_gl)
# Plot ROC Curve
par(mfrow = c(1, 2))  # Set layout to show ROC and PR side by side
plot(roc_curve_gl, col = "blue", main = paste("ROC Curve (AUC =", round(auc_value_gl, 2), ")"))
abline(a = 0, b = 1, lty = 2, col = "gray")
#### Precision-Recall (PR) Curve -------------
# Generate PR curve
pr_curve_gl <- pr.curve(scores.class0 = test_predicted_probs_gl[test_true_labels == 1],
scores.class1 = test_predicted_probs_gl[test_true_labels == 0],
curve = TRUE)
# Plot PR Curve
plot(pr_curve_gl, main = paste("Precision-Recall Curve (AUC =", round(pr_curve_gl$auc.integral, 2), ")"),
col = "red", xlab = "Recall", ylab = "Precision")
#### Choose threshold---------------------------------
threshold_results_gl <- find_optimal_threshold(train_predicted_probs_gl, train_true_labels, thresholds)
threshold_results_gl
plot_metrics(threshold_results_gl)
gl_metrics <- calculate_metrics(test_predicted_probs_gl, test_true_labels, threshold_results_gl$OptimalThreshold)
gl_metrics
#### Confusion Matrix Heatmap-----------
test_predicted_class_gl <- ifelse(test_predicted_probs_gl > threshold_results_gl$OptimalThreshold, 1, 0)
conf_matrix_gl <- table(Predicted = test_predicted_class_gl, Actual = test_true_labels)
ggplot(as.data.frame(conf_matrix_gl), aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
geom_text(aes(label = Freq), color = "black") +
labs(title = "Confusion Matrix Heatmap (Group Lasso)", x = "Actual", y = "Predicted") +
theme_minimal()
# Main Script---------------------------
# Course: Statistical Methods for High Dimensional Data
# Final Project
# 1. Initialize program -------------------------
## 1.1 Load Required Libraries --------------------------------
rm(list=ls())
library(readxl)
library(ggplot2)
library(caret)
library(glmnet)
library(skimr)
library(reshape2)
library(caTools)
library(ResourceSelection)
library(pROC) # For AUC Curve
library(PRROC)    # For Precision-Recall Curve
library(MASS)  # For stepwise regression functions
library(car)
library(gglasso)
library(doParallel)
library(mgcv) # for GAM
library(sparsepca) # for sparse pca
library(e1071) # for SVM
library(dplyr)
library(randomForest)
library(xgboost)
library(Matrix)
library(gridExtra)
library(ggthemes)
library(ROSE)
library(fastDummies)
library(gam)
Sys.setlocale("LC_TIME", "en_US")
## 1.2 Helper functions---------------
# Calculate accuracy, precision, recall, f1 from probabilities and actual
calculate_metrics <- function(predicted_probs, actual_labels, threshold = 0.5) {
# Convert probabilities to binary predictions based on the threshold
predicted_labels <- ifelse(predicted_probs > threshold, 1, 0)
# Create confusion matrix
conf_matrix <- confusionMatrix(factor(predicted_labels), factor(actual_labels))
# Extract components of the confusion matrix
cm <- conf_matrix$table
TP <- cm[2, 2]  # True Positives
FP <- cm[2, 1]  # False Positives
TN <- cm[1, 1]  # True Negatives
FN <- cm[1, 2]  # False Negatives
# Manually calculate metrics
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)
accuracy <- (TP + TN) / sum(cm)
# Return results as a list
return(list(
Precision = precision,
Recall = recall,
F1 = f1_score,
Accuracy = accuracy
))
}
# Function to find the optimal threshold based on probs and actual
find_optimal_threshold <- function(predicted_probs, actual_labels, thresholds) {
results <- data.frame(Threshold = numeric(), Precision = numeric(),
Recall = numeric(), F1 = numeric(), Accuracy = numeric())
for (threshold in thresholds) {
# Safeguard against confusion matrices that don't return 4 cells
tryCatch({
metrics <- calculate_metrics(predicted_probs, actual_labels, threshold)
results <- rbind(results, c(Threshold = threshold, metrics))
}, error = function(e) {})
}
# Convert results to data frame
results <- as.data.frame(results)
# Filter for valid rows (non-NA F1 scores)
results <- results[!is.na(results$F1), ]
# Find the threshold that maximizes F1 score
optimal_threshold <- results$Threshold[which.max(results$F1)]
return(list(OptimalThreshold = optimal_threshold, Metrics = results))
}
# function to plot curves on varios levels of threshold
plot_metrics <- function(metrics) {
# Reshape data for ggplot2
metrics_long <- reshape2::melt(metrics, id.vars = "Threshold",
variable.name = "Metric", value.name = "Value")
# Plot metrics
ggplot(metrics_long, aes(x = Threshold, y = Value, color = Metric)) +
geom_line() +
labs(title = "Metrics Across Thresholds", x = "Threshold", y = "Value") +
theme_minimal()
}
## 1.3 Data and plots paths ---------------------------------
data_path <- "../data/data.xlsx"
plots_dir = "../plots/grid_plots/"
data <- read_excel(data_path)
# 2. Data Preprocessing ------------------------------------
colnames(data)
## 2.1 Additional column: Co-debtor -----------
# before removing ids, use them to check if client has co-debtor
# Aggregate to count distinct 'ID Cliente' by 'No Pagaré Rotativo'
result <- aggregate(`ID Cliente` ~ `No Pagaré Rotativo`, data = data, FUN = function(x) length(unique(x)))
# Rename columns of result
colnames(result) <- c("No Pagaré Rotativo", "Distinct ID Cliente Count")
# View result max count by id
max(result$`Distinct ID Cliente Count`)
# so there is some credits with more than one client associated
# mark if the credit has more than one ID.
# Compute the distinct ID Cliente count per No Pagaré Rotativo
distinct_counts <- aggregate(`ID Cliente` ~ `No Pagaré Rotativo`, data = data, FUN = function(x) length(unique(x)))
# Add a column indicating whether the count is greater than 1
distinct_counts$MoreThanOne <- as.numeric(distinct_counts$`ID Cliente` > 1)
# Merge this information back into the original dataframe
data <- merge(data, distinct_counts[, c("No Pagaré Rotativo", "MoreThanOne")], by = "No Pagaré Rotativo", all.x = TRUE)
colnames(data)
## 2.2 Initial check of the data--------------------
summary(data)
anyNA(data)
## Single-Value columns
# check if there are sing-val col
constant_cols <- sapply(data, function(col) length(unique(col)) == 1)
names(data)[constant_cols]
# remove them
data <- data[, !names(data) %in% "Clasificación Tipo Crédito"]
## Remove ID Variables
id_vars <- c("Código de Crédito", "ID Cliente", "No Pagaré Rotativo")
data <- data[, !names(data) %in% id_vars]
## Rename Columns for Clarity
friendly_names <- c("agency", "status", "rating", "work", "age", "civil_status",
"income_group", "city_born", "max_education", "gender",
"contributions_balance", "credit_limit", "capital_balance",
"capital_due30", "days_due", "date_approval",
"installment", "periodicity", "credit_duration", "date_limit",
"dtf_approval_date", "fx_approval_date", "city_pop_2018","datacredito","default_90", "has_codebtor")
if (length(friendly_names) == ncol(data)) {
colnames(data) <- friendly_names
} else {
stop("Column name mismatch.")
}
## 2.3 Removing AGE  --------------
# remove age because it is a leaker
data <- data[, !names(data) %in% c("age")]
## 2.4 DateTime variables-----------
# Create Derived Variables
data <- data %>%
mutate(
time_difference_days = as.numeric(difftime(as.Date(date_limit), as.Date(date_approval), units = "days"))
)
# First create year, month, day, weekday
# Extract features from the date-time variables
# date approval
data$m_date_approval <- format(data$date_approval, "%m")
data$wd_date_approval <- weekdays(data$date_approval)
# date limit
data$m_date_limit <- format(data$date_limit, "%m")
data$wd_date_limit <- weekdays(data$date_limit)
# Remove date_approval and date_limit:
data <- data[, !(names(data) %in% c("date_approval", "date_limit"))]
## 2.5 capital_due30: -------------
# Represents the amount by which customers have exceeded their credit limit,
### specifically for those who have been overdue for more than 30 days.
### But most of clients have not overdue the credit, so the most of values are 0
# - does not add information to our analysis
# -> It will get transformed to a binary variable 0/1 indicating if a client has overdue the credit in 30+ days
# --> assuming that 30+ days overdue is more likely to progress to 90+ days overdue rather than who's currently at 0 days
data <- data %>%
mutate(
capital_due30_binary = ifelse(capital_due30 > 0, 1, 0)
)
# Remove capital_due30 in order to keep only capital_due30_binary
data <- data[, !names(data) %in% "capital_due30"]
## 2.6 Make "default_90" the last column-----------------------
# Move "default_90" to the last column
data <- data[, c(setdiff(names(data), "default_90"), "default_90")]
## 2.7 Re-clasify cat vars--------------------
# income_group has numbers indicating ascending groups, so it's more appropriate
# to consider it as an ordinal categorical variable instead of a numerical variable
data$income_group <- factor(data$income_group, ordered = TRUE)
## 2.8 Create binary category---------------------
# binary variables should not be considered as numeric variables, so we can detect them and change their class
binary_vars <- names(data)[sapply(data, function(x) all(x %in% c(0, 1)))]
data[binary_vars] <- lapply(data[binary_vars], factor, levels = c(0, 1))
# 3 EDA------------
# Checking distributions on the entire dataset as an initial exploration
## 3.1 Numeric Variables------------
numeric_data <- data %>% select(where(is.numeric))
skim(numeric_data)
### 3.1.1 Histograms------------------
n_cols <- 4
n_rows <- ceiling(length(colnames(numeric_data)) / n_cols)
pdf(paste(plots_dir,"00_EDA__numeric_vars_histograms.pdf", sep=""), width = n_cols * 3, height = n_rows * 3)  # Adjust dimensions
par(mfrow = c(n_rows, n_cols))
for (col_name in colnames(numeric_data)) {
hist(numeric_data[[col_name]], main = paste("Histogram of", col_name),
xlab = col_name, col = "lightblue", border = "black")
}
dev.off()  # Close the PDF device
par(mfrow = c(1, 1))
### 3.1.2 Box Plots---------------
n_cols <- 4
n_rows <- ceiling(length(colnames(numeric_data)) / n_cols)
plots <- list()
for (col_name in colnames(numeric_data)) {
plots[[col_name]] <- ggplot(data, aes(x = factor(default_90), y = .data[[col_name]], fill = factor(default_90))) +
geom_boxplot(alpha = 0.7) +
labs(title = paste("Boxplot of", col_name, "by Target"),
x = "Target",
y = col_name,
fill = "Target") +
theme_minimal()
}
pdf(file = paste(plots_dir, "01_EDA__numeric_vars_boxplots.pdf", sep=""), width = n_cols * 3, height = n_rows * 3)  # Adjust dimensions
grid.arrange(grobs = plots, ncol = n_cols)
dev.off()
### 3.1.3 Density Plots--------------
n_cols <- 4
n_rows <- ceiling(length(colnames(numeric_data)) / n_cols)
plots <- list()
for (col_name in colnames(numeric_data)) {
plots[[col_name]] <- ggplot(data, aes(x = .data[[col_name]], fill = factor(default_90))) +
geom_density(alpha = 0.5) +
labs(title = paste("Density Plot of", col_name), x = col_name, fill = "Target") +
theme_minimal()
}
pdf(file = paste(plots_dir, "02_EDA__numeric_vars_densities.pdf", sep=""), width = n_cols * 3, height = n_rows * 3)  # Adjust dimensions
grid.arrange(grobs = plots, ncol = n_cols)
dev.off()
### 3.1.4 Correlation Matrix -------------------
cor_matrix <- cor(numeric_data, use = "complete.obs")
melted_cor_matrix <- melt(cor_matrix)
melted_cor_matrix <- melted_cor_matrix[as.numeric(melted_cor_matrix$Var1) > as.numeric(melted_cor_matrix$Var2), ]
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
theme_minimal() +
coord_fixed() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
panel.grid = element_blank()  # in order to remove the grid
) +
scale_x_discrete(limits = unique(melted_cor_matrix$Var1)) +
scale_y_discrete(limits = unique(melted_cor_matrix$Var2))
## 3.2 Non-Numeric Variables------------
non_numeric_data <- data %>% select(where(~ !is.numeric(.)))
unique_counts <- sapply(non_numeric_data, function(x) length(unique(x)))
mode_values <- sapply(non_numeric_data, function(x) names(which.max(table(x))))
print(mode_values)
### 3.2.1 Bar Plots for non numeric variables------------
n_cols <- 5
n_rows <- ceiling(length(names(non_numeric_data)) / n_cols)
plots <- list()
for (col_name in names(non_numeric_data)) {
plots[[col_name]] <- ggplot(non_numeric_data, aes_string(x = col_name)) +
geom_bar(fill = "skyblue", color = "black") +
labs(title = paste("Bar Plot of", col_name),
x = col_name,
y = "Frequency") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
pdf(file = paste(plots_dir, "03_EDA__non_numeric_vars_barplots.pdf", sep = ""), width = n_cols * 3, height = n_rows * 3)
grid.arrange(grobs = plots, ncol = n_cols)
dev.off()
#check for labels with too low values (I've seen it from barplots)
table(non_numeric_data$periodicity)
#bimensual has only 1 observation -> let's remove it from the dataset (not statistically representative)
data <- data[data$periodicity != "bimensual", ]
#updating also the non_numeric_data
non_numeric_data <- non_numeric_data[rownames(non_numeric_data) %in% rownames(data), ]
### 3.2.2 Proportional target barplots by value for non numeric variables------------
n_cols <- 4
n_rows <- ceiling(length(colnames(numeric_data)) / n_cols)
plots <- list()
for (col_name in colnames(non_numeric_data)) {
plots[[col_name]] <- ggplot(data, aes_string(x = col_name, fill = "factor(default_90)")) +
geom_bar(position = "fill") +  # Use position = "dodge" for side-by-side bars
labs(title = paste("Bar Plot of", col_name, "by Target"),
x = col_name, y = "Proportion", fill = "Target") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
pdf(file = paste(plots_dir, "04_EDA__non_numeric_vars_target_proportions.pdf", sep=""), width = n_cols * 4, height = n_rows * 5)  # Adjust dimensions
grid.arrange(grobs = plots, ncol = n_cols)
dev.off()
### 3.2.3 Chi Squared------------
# The output will show the Chi-square statistic, degrees of freedom, and the p-value.
# A p-value less than 0.05 indicates that there is a significant association
# between the non-numeric variable and the target variable default_90.
# Create a vector to store p-values
p_values <- c()
# Perform Chi-square tests and collect p-values
for (col_name in colnames(non_numeric_data)) {
contingency_table <- table(non_numeric_data[[col_name]], data$default_90)
chi2_result <- chisq.test(contingency_table)
# Store the p-value
p_values <- c(p_values, chi2_result$p.value)
}
# Create a data frame for plotting
chi2_results_df <- data.frame(
Variable = colnames(non_numeric_data),
P_value = p_values
)
# Plot the p-values
ggplot(chi2_results_df, aes(x = reorder(Variable, -P_value), y = P_value)) +
geom_bar(stat = "identity", fill = "skyblue") +
geom_hline(yintercept = 0.05, color = "red", linetype = "dashed") +  # Significance threshold
labs(title = "P-values from Chi-square Tests for Non-numeric Variables vs default_90",
x = "Variable",
y = "P-value") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
## 3.3 Transformations ---------------------------------------
# Applying log transformation only to too much skewed features bc for the others could be sufficient the scaling
data$contributions_balance <- log1p(data$contributions_balance)
data$credit_limit <- log1p(data$credit_limit)
data$capital_balance <- log1p(data$capital_balance)
data$installment <- log1p(data$installment)
data$time_difference_days <- log1p(data$time_difference_days)
data$days_due <- log1p(data$days_due)
data$city_pop_2018 <- log1p(data$city_pop_2018)
# Distributions after the log-transformations (again on the entire dataset)
# update numeric_data that is the data we use for histograms
numeric_data <- data[sapply(data, is.numeric)]
### 3.3.1 Histograms--------------
n_cols <- 4
n_rows <- ceiling(length(colnames(numeric_data)) / n_cols)
pdf(paste(plots_dir,"05_EDA__numeric_vars_after_log_histograms.pdf", sep=""), width = n_cols * 3, height = n_rows * 3)  # Adjust dimensions
par(mfrow = c(n_rows, n_cols))
for (col_name in colnames(numeric_data)) {
hist(data[[col_name]], main = paste("Histogram of", col_name),
xlab = col_name, col = "lightblue", border = "black")
}
dev.off()  # Close the PDF device
par(mfrow = c(1, 1))
### 3.3.2 Box Plots---------------
n_cols <- 4
n_rows <- ceiling(length(colnames(numeric_data)) / n_cols)
plots <- list()
for (col_name in colnames(numeric_data)) {
plots[[col_name]] <- ggplot(data, aes(x = factor(default_90), y = .data[[col_name]], fill = factor(default_90))) +
geom_boxplot(alpha = 0.7) +
labs(title = paste("Boxplot of", col_name, "by Target"),
x = "Target",
y = col_name,
fill = "Target") +
theme_minimal()
}
pdf(file = paste(plots_dir, "06_EDA__numeric_vars_after_log_boxplots.pdf", sep=""), width = n_cols * 3, height = n_rows * 3)  # Adjust dimensions
grid.arrange(grobs = plots, ncol = n_cols)
dev.off()
### 3.3.3 Density Plots--------------
n_cols <- 4
n_rows <- ceiling(length(colnames(numeric_data)) / n_cols)
plots <- list()
for (col_name in colnames(numeric_data)) {
plots[[col_name]] <- ggplot(data, aes(x = .data[[col_name]], fill = factor(default_90))) +
geom_density(alpha = 0.5) +
labs(title = paste("Density Plot of", col_name), x = col_name, fill = "Target") +
theme_minimal()
}
pdf(file = paste(plots_dir, "07_EDA__numeric_vars_after_log_densities.pdf", sep=""), width = n_cols * 3, height = n_rows * 3)  # Adjust dimensions
grid.arrange(grobs = plots, ncol = n_cols)
dev.off()
# 4. Train-Test Split --------------------------------------
set.seed(123)
split <- sample.split(data$default_90, SplitRatio = 0.7)
train_data <- subset(data, split)
test_data <- subset(data, !split)
# 5. Scaling -----------------
# Exclude binary variables and the target from the numeric_data dataframe -> already done previously
vars_to_scale <- colnames(numeric_data)
test_data_scaled <- test_data
train_data_scaled <- train_data
preproc <- preProcess(train_data[vars_to_scale], method = c("center", "scale"))
train_data_scaled[vars_to_scale] <- predict(preproc, train_data[vars_to_scale])
test_data_scaled [vars_to_scale] <- predict(preproc, test_data [vars_to_scale])
# 6. Oversampling ------------------------
## Oversampling of minority class
# Check how much unbalanced the data are
table(train_data_scaled$default_90)
train_data_balanced <- ovun.sample(default_90 ~ ., data = train_data_scaled, method = "over")$data
table(train_data_balanced$default_90)
train_data_scaled <- train_data_balanced # rename it to avoid changing many names
# True labels
test_true_labels  <- test_data_scaled$default_90 # for model evaluation
train_true_labels <- train_data_scaled$default_90 # for model evaluation
# Define a range of thresholds to evaluate
thresholds <- seq(0, 1, by = 0.05)
### 8.4.1 Prepare data-------------
train_data_scaled$default_90 <- factor(train_data_scaled$default_90, levels = c(0, 1))
test_data_scaled$default_90 <- factor(test_data_scaled$default_90, levels = c(0, 1))
train_matrix <- model.matrix(default_90 ~ . - 1, data = train_data_scaled)
test_matrix <- model.matrix(default_90 ~ . - 1, data = test_data_scaled)
# Align columns between train and test matrices
missing_in_test <- setdiff(colnames(train_matrix), colnames(test_matrix))
for (col in missing_in_test) {
test_matrix <- cbind(test_matrix, setNames(data.frame(rep(0, nrow(test_matrix))), col))
}
test_matrix <- test_matrix[, colnames(train_matrix)]  # Reorder columns
test_matrix <- as.matrix(test_matrix)
# Extract labels
train_labels <- as.numeric(train_data_scaled$default_90) - 1
test_labels <- as.numeric(test_data_scaled$default_90) - 1
# Create DMatrix
dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)
dtest <- xgb.DMatrix(data = test_matrix, label = test_labels)
### 8.4.2 Train Model----------------
# Define XGBoost parameters
params <- list(
objective = "binary:logistic",  # Binary classification
eval_metric = "logloss",        # Evaluation metric
eta = 0.1,                      # Learning rate
max_depth = 6,                  # Maximum depth of trees
gamma = 0,                      # Minimum loss reduction
colsample_bytree = 0.8,         # Column subsample ratio
subsample = 0.8                 # Row subsample ratio
)
# Train the XGBoost model
xgb_model <- xgb.train(
params = params,
data = dtrain,
nrounds = 100,                  # Number of boosting rounds
watchlist = list(train = dtrain, test = dtest),
early_stopping_rounds = 10,    # Early stopping
print_every_n = 10             # Print progress every 10 rounds
)
### 8.4.3 Evaluate Model-------------
# Predict probabilities on test data
pred_probs_xgb <- predict(xgb_model, newdata = dtest)
xgb_metrics <- calculate_metrics(pred_probs_xgb, test_true_labels)
xgb_metrics
#### ROC Curve and AUC-------------------
# Generate the ROC curve and calculate AUC
roc_curve_xgb <- roc(test_true_labels, pred_probs_xgb)
auc_value_xgb <- auc(roc_curve_xgb)
# Plot ROC Curve
par(mfrow = c(1, 2))  # Layout for side-by-side plots
plot(roc_curve_xgb, col = "blue", main = paste("ROC Curve (AUC =", round(auc_value_xgb, 2), ")"))
abline(a = 0, b = 1, lty = 2, col = "gray")
#### Precision-Recall (PR) Curve--------------
# Generate PR curve
pr_curve_xgb <- pr.curve(scores.class0 = pred_probs_xgb[test_true_labels == 1],
scores.class1 = pred_probs_xgb[test_true_labels == 0],
curve = TRUE)
# Plot PR Curve
plot(pr_curve_xgb, main = paste("Precision-Recall Curve (AUC =", round(pr_curve_xgb$auc.integral, 2), ")"),
col = "red", xlab = "Recall", ylab = "Precision")
threshold <- 0.50
predicted_class <- ifelse(pred_probs_xgb > threshold, 1, 0)
# Create confusion matrix
conf_matrix <- table(Predicted = predicted_class, Actual = test_data$default_90)
conf_matrix_df <- as.data.frame(as.table(conf_matrix))
# Plot heatmap
ggplot(conf_matrix_df, aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
geom_text(aes(label = Freq), color = "black") +
labs(
title = "Confusion Matrix Heatmap",
x = "Actual",
y = "Predicted"
) +
theme_minimal()
