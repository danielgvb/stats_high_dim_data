labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
theme_minimal()
#### (2) Confusion Matrix Heatmap-------------
predicted_class <- ifelse(predicted_probs_en > 0.15, 1, 0) # using optimal threshold
conf_matrix <- table(Predicted = predicted_class, Actual = y_test)
ggplot(as.data.frame(conf_matrix), aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
geom_text(aes(label = Freq), color = "black") +
labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
theme_minimal()
#### (2) Confusion Matrix Heatmap-------------
predicted_class <- ifelse(predicted_probs_en > 0.25, 1, 0) # using optimal threshold
conf_matrix <- table(Predicted = predicted_class, Actual = y_test)
ggplot(as.data.frame(conf_matrix), aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
geom_text(aes(label = Freq), color = "black") +
labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
theme_minimal()
#### (3) Coefficient Plot------------
coef_data <- as.data.frame(as.matrix(coef(elastic_net_model, s = lambda_min)))
coef_data$Variable <- rownames(coef_data)
colnames(coef_data) <- c("Coefficient", "Variable")
coef_data <- coef_data %>% filter(Coefficient != 0 & Variable != "(Intercept)")
ggplot(coef_data, aes(x = reorder(Variable, Coefficient), y = Coefficient)) +
geom_bar(stat = "identity", fill = "lightblue") +
coord_flip() +
labs(title = "Elastic Net Coefficient Plot", x = "Variable", y = "Coefficient") +
theme_minimal()
### 1. Prepare Data for Group Lasso -------------------------
# Define groups for numeric and factor variables
# Train Set
train_data_no_target <- train_data[, !colnames(train_data) %in% "default_90"]
numeric_data_train <- train_data_no_target[sapply(train_data_no_target, is.numeric)]
non_numeric_data_train <- train_data_no_target[, !sapply(train_data_no_target, is.numeric)]
group_vector_train <- c()  # Stores group IDs
dummy_list_train <- list()  # Stores dummy variables
group_id <- 1
# Numeric variables (each variable is its own group)
group_vector_train <- c(group_vector_train, rep(group_id, ncol(numeric_data_train)))
group_id <- group_id + 1
# Factor variables (each factor's dummies are a group)
for (col_name in colnames(non_numeric_data_train)) {
# Create dummy variables, dropping the first level
dummies <- model.matrix(as.formula(paste("~", col_name)), data = train_data_no_target)[, -1]
# Ensure dummies is treated as a matrix
dummies <- as.matrix(dummies)
# Check if the resulting dummies matrix has at least one column
if (!is.null(ncol(dummies)) && ncol(dummies) > 0) {
# Store the dummies in the list
dummy_list_train[[col_name]] <- dummies
# Add group markers for the current set of dummy variables
group_vector_train <- c(group_vector_train, rep(group_id, ncol(dummies)))
# Increment the group ID for the next factor
group_id <- group_id + 1
} else {
# Handle cases where no dummy variables are created (e.g., single-level factors)
warning(paste("No dummy variables created for", col_name, "as it has only one level."))
}
}
# Combine numeric and dummy data for the train set
dummy_data_train <- do.call(cbind, dummy_list_train)
combined_data_train <- cbind(numeric_data_train, dummy_data_train)
X_train <- as.matrix(combined_data_train)
group_vector_train
# Combine numeric and dummy data for the train set
dummy_data_train <- do.call(cbind, dummy_list_train)
combined_data_train <- cbind(numeric_data_train, dummy_data_train)
X_train <- as.matrix(combined_data_train)
y_train <- ifelse(train_data$default_90 == 1, 1, -1)  # Convert target to {-1, 1}
X_train
View(X_train)
### 1. Prepare Data for Group Lasso -------------------------
# Define groups for numeric and factor variables
# Train Set
train_data_no_target <- train_data[, !colnames(train_data) %in% "default_90"]
numeric_data_train <- train_data_no_target[sapply(train_data_no_target, is.numeric)]
non_numeric_data_train <- train_data_no_target[, !sapply(train_data_no_target, is.numeric)]
group_vector_train <- c()  # Stores group IDs
dummy_list_train <- list()  # Stores dummy variables
group_id <- 1
group_vector_train
# Numeric variables (each variable is its own group)
group_vector_train <- c(group_vector_train, rep(group_id, ncol(numeric_data_train)))
group_id <- group_id + 1
group_vector_train
### 1. Prepare Data for Group Lasso -------------------------
# Define groups for numeric and factor variables
# Train Set
train_data_no_target <- train_data[, !colnames(train_data) %in% "default_90"]
numeric_data_train <- train_data_no_target[sapply(train_data_no_target, is.numeric)]
non_numeric_data_train <- train_data_no_target[, !sapply(train_data_no_target, is.numeric)]
group_vector_train <- c()  # Stores group IDs
dummy_list_train <- list()  # Stores dummy variables
group_id <- 1
# Numeric variables (each variable is its own group)
group_vector_train <- c(group_vector_train, seq(group_id, length.out = ncol(numeric_data_train)))
group_vector_train
group_id <- max(group_vector_train) + 1
group_id
# Factor variables (each factor's dummies are a group)
for (col_name in colnames(non_numeric_data_train)) {
# Create dummy variables, dropping the first level
dummies <- model.matrix(as.formula(paste("~", col_name)), data = train_data_no_target)[, -1]
# Ensure dummies is treated as a matrix
dummies <- as.matrix(dummies)
# Check if the resulting dummies matrix has at least one column
if (!is.null(ncol(dummies)) && ncol(dummies) > 0) {
# Store the dummies in the list
dummy_list_train[[col_name]] <- dummies
# Add group markers for the current set of dummy variables
group_vector_train <- c(group_vector_train, rep(group_id, ncol(dummies)))
# Increment the group ID for the next factor
group_id <- group_id + 1
} else {
# Handle cases where no dummy variables are created (e.g., single-level factors)
warning(paste("No dummy variables created for", col_name, "as it has only one level."))
}
}
# Combine numeric and dummy data for the train set
dummy_data_train <- do.call(cbind, dummy_list_train)
combined_data_train <- cbind(numeric_data_train, dummy_data_train)
X_train <- as.matrix(combined_data_train)
y_train <- ifelse(train_data$default_90 == 1, 1, -1)  # Convert target to {-1, 1}
View(X_train)
# Test Set
test_data_no_target <- test_data[, !colnames(test_data) %in% "default_90"]
numeric_data_test <- test_data_no_target[sapply(test_data_no_target, is.numeric)]
non_numeric_data_test <- test_data_no_target[, !sapply(test_data_no_target, is.numeric)]
group_vector_test <- c()
dummy_list_test <- list()
group_id <- 1
# Numeric variables
group_vector_test <- c(group_vector_test, seq(group_id, length.out = ncol(numeric_data_test)))
group_id <- max(group_vector_test) + 1
# Factor variables
for (col_name in colnames(non_numeric_data_test)) {
dummies <- model.matrix(as.formula(paste("~", col_name)), data = test_data_no_target)[, -1]
dummies <- as.matrix(dummies)
if (!is.null(ncol(dummies)) && ncol(dummies) > 0) {
dummy_list_test[[col_name]] <- dummies
group_vector_test <- c(group_vector_test, rep(group_id, ncol(dummies)))
group_id <- group_id + 1
} else {
warning(paste("No dummy variables created for", col_name, "as it has only one level."))
}
}
# Combine numeric and dummy data for the test set
dummy_data_test <- do.call(cbind, dummy_list_test)
combined_data_test <- cbind(numeric_data_test, dummy_data_test)
X_test <- as.matrix(combined_data_test)
y_test <- ifelse(test_data$default_90 == 1, 1, -1)  # Convert target to {-1, 1}
### 2. Standardize Predictors ---------------------------------
X_train_scaled <- scale(X_train)
X_test_scaled <- scale(X_test)
# Set up parallel processing
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
# Fit group lasso model
fit_gglasso <- gglasso(
x = X_train_scaled,
y = y_train,
group = group_vector_train,
loss = "logit",
nlambda = 50
)
# Stop parallel processing
stopCluster(cl)
# Plot Group Lasso Fit
plot(fit_gglasso, main = "Group Lasso Coefficients Across Lambda")
# Plot Group Lasso Fit
par(mfrow=c(1,1))
plot(fit_gglasso, main = "Group Lasso Coefficients Across Lambda")
### 4. Perform Cross-Validation for Group Lasso -----------------
set.seed(123)
### 4. Perform Cross-Validation for Group Lasso -----------------
set.seed(123)
cv_fit_gglasso <- cv.gglasso(
x = X_train_scaled,
y = y_train,
group = group_vector_train,
loss = "logit",
nfolds = 10
)
# Optimal lambda
lambda_min_gl <- cv_fit_gglasso$lambda.min
cat("Optimal lambda (min):", lambda_min_gl, "\n")
# Optimal lambda
lambda_min_gl <- cv_fit_gglasso$lambda.min
lambda_1se_gl <- cv_fit_gglasso$lambda.1se
cat("Optimal lambda (min):", lambda_min_gl, "\n")
cat("Optimal lambda (1se):", lambda_1se_gl, "\n")
# Plot Cross-Validation Results for Group Lasso
plot(cv_fit_gglasso, main = "Cross-Validation for Group Lasso")
abline(v = log(lambda_min_gl), col = "blue", lty = 2, lwd = 2)  # Vertical line for lambda.min
abline(v = log(lambda_1se_gl), col = "red", lty = 2, lwd = 2)   # Vertical line for lambda.1se
legend("topright", legend = c("lambda.min", "lambda.1se"), col = c("blue", "red"), lty = 2, lwd = 2)
### 5. Fit the Final Group Lasso Model -------------------------
group_lasso_model <- gglasso(
x = X_train_scaled,
y = y_train,
group = group_vector_train,
loss = "logit",
lambda = lambda_min_gl
)
plot(group_lasso_model, main = "Group Lasso Coefficients Across Lambda")
plot(group_lasso_model)
# Plot Cross-Validation Results for Group Lasso
plot(cv_fit_gglasso, main = "Cross-Validation for Group Lasso")
abline(v = log(lambda_min_gl), col = "blue", lty = 2, lwd = 2)  # Vertical line for lambda.min
abline(v = log(lambda_1se_gl), col = "red", lty = 2, lwd = 2)   # Vertical line for lambda.1se
legend("topright", legend = c("lambda.min", "lambda.1se"), col = c("blue", "red"), lty = 2, lwd = 2)
### 5. Fit the Final Group Lasso Model -------------------------
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
group_lasso_model <- gglasso(
x = X_train_scaled,
y = y_train,
group = group_vector_train,
loss = "logit",
lambda = lambda_min_gl
)
stopCluster(cl)
group_lasso_model$beta
group_lasso_model$beta
### 6. Evaluate Group Lasso Model ------------------------------
# Predicted probabilities
probs_gl <- predict(group_lasso_model, newx = X_test_scaled, type = "link")
### 6. Evaluate Group Lasso Model ------------------------------
# Predicted probabilities
log_odds_gl <- predict(group_lasso_model, newx = X_test_scaled, type = "link")
log_odds_gl
predicted_probs_gl <- 1 / (1 + exp(-log_odds_gl))
predicted_probs_gl
gl_metrics <- calculate_metrics(predicted_probs_gl, test_data$default_90)
gl_metrics
### 7. Post-Estimation Plots for Group Lasso -------------------
y_test_binary <- test_data$default_90
y_test_binary
#### (1) ROC Curve and AUC-------------
roc_curve_gl <- roc(y_test_binary, predicted_prob_gl)
auc_value_gl <- auc(roc_curve_gl)
# Plot ROC Curve
par(mfrow = c(1, 2))  # Set layout to show ROC and PR side by side
plot(roc_curve_gl, col = "blue", main = paste("ROC Curve (AUC =", round(auc_value_gl, 2), ")"))
abline(a = 0, b = 1, lty = 2, col = "gray")
#### (1) ROC Curve and AUC-------------
roc_curve_gl <- roc(y_test_binary, predicted_probs_gl)
auc_value_gl <- auc(roc_curve_gl)
# Plot ROC Curve
par(mfrow = c(1, 2))  # Set layout to show ROC and PR side by side
plot(roc_curve_gl, col = "blue", main = paste("ROC Curve (AUC =", round(auc_value_gl, 2), ")"))
abline(a = 0, b = 1, lty = 2, col = "gray")
#### (2) Precision-Recall (PR) Curve -------------
# Generate PR curve
pr_curve_gl <- pr.curve(scores.class0 = predicted_probs_gl[y_test_binary == 1],
scores.class1 = predicted_probs_gl[y_test_binary == 0],
curve = TRUE)
# Plot PR Curve
plot(pr_curve_gl, main = paste("Precision-Recall Curve (AUC =", round(pr_curve_gl$auc.integral, 2), ")"),
col = "red", xlab = "Recall", ylab = "Precision")
# Optimize threshold
threshold_results_gl <- find_optimal_threshold(predicted_probs_gl, true_labels, thresholds)
threshold_results_gl
plot_metrics(threshold_results_gl)
#### (2) Confusion Matrix Heatmap-----------
predicted_class_gl <- ifelse(predicted_prob_gl > 0.25, 1, -1)
conf_matrix_gl <- table(Predicted = predicted_class_gl, Actual = y_test)
ggplot(as.data.frame(conf_matrix_gl), aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
geom_text(aes(label = Freq), color = "black") +
labs(title = "Confusion Matrix Heatmap (Group Lasso)", x = "Actual", y = "Predicted") +
theme_minimal()
#### (2) Confusion Matrix Heatmap-----------
predicted_class_gl <- ifelse(predicted_probs_gl > 0.25, 1, -1)
conf_matrix_gl <- table(Predicted = predicted_class_gl, Actual = y_test)
ggplot(as.data.frame(conf_matrix_gl), aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
geom_text(aes(label = Freq), color = "black") +
labs(title = "Confusion Matrix Heatmap (Group Lasso)", x = "Actual", y = "Predicted") +
theme_minimal()
#### (3) Coefficient Plot---------------
coef_data_gl <- as.data.frame(as.matrix(coef(group_lasso_model)))
coef_data_gl$Variable <- rownames(coef_data_gl)
colnames(coef_data_gl) <- c("Coefficient", "Variable")
coef_data_gl <- coef_data_gl %>% filter(Coefficient != 0 & Variable != "(Intercept)")
ggplot(coef_data_gl, aes(x = reorder(Variable, Coefficient), y = Coefficient)) +
geom_bar(stat = "identity", fill = "lightblue") +
coord_flip() +
labs(title = "Group Lasso Coefficient Plot", x = "Variable", y = "Coefficient") +
theme_minimal()
# Convert coefficients to data frame and filter
coef_data_gl <- as.data.frame(as.matrix(coef(group_lasso_model)))
coef_data_gl$Variable <- rownames(coef_data_gl)
colnames(coef_data_gl) <- c("Coefficient", "Variable")
coef_data_gl <- coef_data_gl %>%
filter(Coefficient != 0 & Variable != "(Intercept)")
# Select top N coefficients by absolute value
top_n <- 20  # Adjust this number to show more/less coefficients
coef_data_gl <- coef_data_gl %>%
mutate(AbsCoefficient = abs(Coefficient)) %>%
arrange(desc(AbsCoefficient)) %>%
slice(1:top_n)
# Plot the top N coefficients
ggplot(coef_data_gl, aes(x = reorder(Variable, Coefficient), y = Coefficient)) +
geom_bar(stat = "identity", fill = "lightblue") +
coord_flip() +
labs(title = "Group Lasso Top Coefficients Plot",
x = "Variable", y = "Coefficient") +
theme_minimal()
# Top 20 coefficients Group Lasso
# Convert coefficients to data frame and filter
coef_data_gl <- as.data.frame(as.matrix(coef(group_lasso_model)))
coef_data_gl$Variable <- rownames(coef_data_gl)
colnames(coef_data_gl) <- c("Coefficient", "Variable")
coef_data_gl <- coef_data_gl %>%
filter(Coefficient != 0 & Variable != "(Intercept)")
# Select top N coefficients by absolute value
top_n <- 20  # Adjust this number to show more/less coefficients
coef_data_gl <- coef_data_gl %>%
mutate(AbsCoefficient = abs(Coefficient)) %>%
arrange(desc(AbsCoefficient)) %>%
slice(1:top_n)
# Plot the top N coefficients
ggplot(coef_data_gl, aes(x = reorder(Variable, Coefficient), y = Coefficient)) +
geom_bar(stat = "identity", fill = "lightblue") +
coord_flip() +
labs(title = "Group Lasso Top Coefficients Plot",
x = "Variable", y = "Coefficient") +
theme_minimal()
# Select top N coefficients by absolute value
top_n <- 25  # Adjust this number to show more/less coefficients
coef_data_gl <- coef_data_gl %>%
mutate(AbsCoefficient = abs(Coefficient)) %>%
arrange(desc(AbsCoefficient)) %>%
slice(1:top_n)
# Plot the top N coefficients
ggplot(coef_data_gl, aes(x = reorder(Variable, Coefficient), y = Coefficient)) +
geom_bar(stat = "identity", fill = "lightblue") +
coord_flip() +
labs(title = "Group Lasso Top Coefficients Plot",
x = "Variable", y = "Coefficient") +
theme_minimal()
# Select top N coefficients by absolute value
top_n <- 15  # Adjust this number to show more/less coefficients
coef_data_gl <- coef_data_gl %>%
mutate(AbsCoefficient = abs(Coefficient)) %>%
arrange(desc(AbsCoefficient)) %>%
slice(1:top_n)
# Plot the top N coefficients
ggplot(coef_data_gl, aes(x = reorder(Variable, Coefficient), y = Coefficient)) +
geom_bar(stat = "identity", fill = "lightblue") +
coord_flip() +
labs(title = "Group Lasso Top Coefficients Plot",
x = "Variable", y = "Coefficient") +
theme_minimal()
# Select top N coefficients by absolute value
top_n <- 5  # Adjust this number to show more/less coefficients
coef_data_gl <- coef_data_gl %>%
mutate(AbsCoefficient = abs(Coefficient)) %>%
arrange(desc(AbsCoefficient)) %>%
slice(1:top_n)
# Plot the top N coefficients
ggplot(coef_data_gl, aes(x = reorder(Variable, Coefficient), y = Coefficient)) +
geom_bar(stat = "identity", fill = "lightblue") +
coord_flip() +
labs(title = "Group Lasso Top Coefficients Plot",
x = "Variable", y = "Coefficient") +
theme_minimal()
## GAM Model----------------
# Using most relevant poly order (`s()` indicates the poly order for each predictor)
gam_model <- gam(default_90 ~ s(contributions_balance) + s(installment) + s(capital_balance) + s(credit_limit) + gender + income_group  ,
data = train_data,
family = binomial)
# STOP HERE-------------------------------------------
# from this point onwards is pending adjustments
## GAM Model----------------
# Using most relevant poly order (`s()` indicates the poly order for each predictor)
gam_model <- gam(default_90 ~ s(contributions_balance) + s(installment) + s(capital_balance) + s(credit_limit) + gender + income_group  ,
data = train_data,
family = binomial)
# Summary of GAM Model
summary(gam_model)
### Model Evaluation----------
predicted_probs_gam <- predict(gam_model, newdata = test_data, type = "response")
### Model Evaluation-------------------
predicted_probs_gam <- predict(gam_model, newdata = test_data, type = "response")
gam_metrics <- calculate_metrics(predicted_probs_gam, test_data$default_90)
gam_metrics
gam_metrics <- calculate_metrics(predicted_probs_gam, test_data$default_90, 0.3)
gam_metrics
# Threshold optimization
threshold_results_gam <- find_optimal_threshold(predicted_probs_gam, true_labels, thresholds)
threshold_results_gam
plot_metrics(threshold_results_gam)
# True labels
y_test <- test_data$default_90
#### (1) ROC Curve and AUC-------------
roc_curve_gam <- roc(y_test, predicted_probs_gam)
auc_value_gam <- auc(roc_curve_gam)
# Plot ROC Curve
par(mfrow = c(1, 2))  # Set layout to show ROC and PR curves side by side
plot(roc_curve_gam, col = "blue", main = paste("ROC Curve (AUC =", round(auc_value_gam, 2), ")"))
abline(a = 0, b = 1, lty = 2, col = "gray")
# Filter predicted probabilities based on the true labels
scores_class0 <- predicted_probs_gam[test_data$default_90 == 1]
scores_class1 <- predicted_probs_gam[test_data$default_90 == 0]
# Make sure the filtered vectors are numeric
scores_class0 <- as.numeric(scores_class0)
scores_class1 <- as.numeric(scores_class1)
pr_curve <- pr.curve(scores.class0 = scores_class0,
scores.class1 = scores_class1,
curve = TRUE)
plot(pr_curve, main = paste("Precision-Recall Curve (AUC =", round(pr_curve$auc.integral, 2), ")"),
col = "red", xlab = "Recall", ylab = "Precision")
# this model sucks, lets try adjusting threshold
### Fine Tunning Threshold------------
# Predicted Probabilities from GAM Model
# Threshold optimization
threshold_results_gam <- find_optimal_threshold(predicted_probs_gam, true_labels, thresholds)
threshold_results_gam
plot_metrics(threshold_results_gam)
#### 2. Confusion Matrix Heatmap -----------------------------
# Predicted classes
predicted_class <- ifelse(predicted_probs_gam > 0.15, 1, 0)
# Confusion matrix
conf_matrix <- table(Predicted = predicted_class, Actual = test_data$default_90)
# Heatmap
ggplot(as.data.frame(conf_matrix), aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
geom_text(aes(label = Freq), color = "black") +
labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
theme_minimal()
#### 2. Confusion Matrix Heatmap -----------------------------
# Predicted classes
predicted_class <- ifelse(predicted_probs_gam > 0.2, 1, 0)
# Confusion matrix
conf_matrix <- table(Predicted = predicted_class, Actual = test_data$default_90)
# Heatmap
ggplot(as.data.frame(conf_matrix), aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
geom_text(aes(label = Freq), color = "black") +
labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
theme_minimal()
#### 2. Confusion Matrix Heatmap -----------------------------
# Predicted classes
predicted_class <- ifelse(predicted_probs_gam > 0.25, 1, 0)
# Confusion matrix
conf_matrix <- table(Predicted = predicted_class, Actual = test_data$default_90)
# Heatmap
ggplot(as.data.frame(conf_matrix), aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
geom_text(aes(label = Freq), color = "black") +
labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
theme_minimal()
## GAM Model----------------
# Using most relevant poly order (`s()` indicates the poly order for each predictor)
gam_model <- gam(default_90 ~ s(contributions_balance) + s(installment) + s(capital_balance) + s(credit_limit) + gender + income_group  ,
data = train_data,
family = binomial)
## GAM Model----------------
# Using most relevant poly order (`s()` indicates the poly order for each predictor)
gam_model <- gam(default_90 ~ s(contributions_balance) + s(installment) + s(capital_balance) + s(credit_limit) + s(days_due)+ status+ wd_date_limit + gender + income_group  ,
data = train_data,
family = binomial)
plot(gam_model, pages = 1, rug = TRUE)
# Summary of GAM Model
summary(gam_model)
### Model Evaluation-------------------
predicted_probs_gam <- predict(gam_model, newdata = test_data, type = "response")
gam_metrics <- calculate_metrics(predicted_probs_gam, test_data$default_90, 0.3)
gam_metrics
# True labels
y_test <- test_data$default_90
#### (1) ROC Curve and AUC-------------
roc_curve_gam <- roc(y_test, predicted_probs_gam)
auc_value_gam <- auc(roc_curve_gam)
# Plot ROC Curve
par(mfrow = c(1, 2))  # Set layout to show ROC and PR curves side by side
plot(roc_curve_gam, col = "blue", main = paste("ROC Curve (AUC =", round(auc_value_gam, 2), ")"))
abline(a = 0, b = 1, lty = 2, col = "gray")
# Filter predicted probabilities based on the true labels
scores_class0 <- predicted_probs_gam[test_data$default_90 == 1]
scores_class1 <- predicted_probs_gam[test_data$default_90 == 0]
# Make sure the filtered vectors are numeric
scores_class0 <- as.numeric(scores_class0)
scores_class1 <- as.numeric(scores_class1)
pr_curve <- pr.curve(scores.class0 = scores_class0,
scores.class1 = scores_class1,
curve = TRUE)
plot(pr_curve, main = paste("Precision-Recall Curve (AUC =", round(pr_curve$auc.integral, 2), ")"),
col = "red", xlab = "Recall", ylab = "Precision")
# this model sucks, lets try adjusting threshold
### Fine Tunning Threshold------------
threshold_results_gam <- find_optimal_threshold(predicted_probs_gam, true_labels, thresholds)
threshold_results_gam
plot_metrics(threshold_results_gam)
# Confusion matrix
conf_matrix <- table(Predicted = predicted_class, Actual = test_data$default_90)
# Heatmap
ggplot(as.data.frame(conf_matrix), aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
geom_text(aes(label = Freq), color = "black") +
labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
theme_minimal()
